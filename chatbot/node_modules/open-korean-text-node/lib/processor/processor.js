"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const Java = require("java");
const classes_1 = require("../classes");
const tokens_1 = require("./tokens");
class OpenKoreanTextProcessor extends classes_1.AbstractJavaClass {
    static ensureJvm() {
        if (arguments[0] && typeof arguments[0] == 'function') {
            return Java.ensureJvm(arguments[0]);
        }
        else {
            return new Promise((resolve, reject) => Java.ensureJvm((err) => (err ? reject(err) : resolve())));
        }
    }
    static isJvmCreated() {
        return Java.isJvmCreated();
    }
    static normalize(text) {
        return this.class.normalizePromise(text);
    }
    static normalizeSync(text) {
        return this.class.normalize(text);
    }
    static tokenize(text) {
        return this.class.tokenizePromise(text).then((tokensSeq) => tokens_1.IntermediaryTokensObject.wrap(tokensSeq));
    }
    static tokenizeSync(text) {
        return tokens_1.IntermediaryTokensObject.wrap(this.class.tokenize(text));
    }
    static addNounsToDictionary() {
        const listObject = new classes_1.ArrayList(Array.from(arguments));
        return this.class.addNounsToDictionaryPromise(listObject.interface);
    }
    static addNounsToDictionarySync() {
        const listObject = new classes_1.ArrayList(Array.from(arguments));
        return this.class.addNounsToDictionary(listObject.interface);
    }
    static tokensToJsonArray(tokens, keepSpace) {
        return new Promise((resolve, reject) => {
            try {
                resolve(this.tokensToJsonArraySync(tokens, keepSpace));
            }
            catch (error) {
                reject(error);
            }
        });
    }
    static tokensToJsonArraySync(tokens, keepSpace) {
        const list = tokens.toJSON();
        return keepSpace ? list : list.filter((token) => token.pos !== 'Space');
    }
    static splitSentences(text) {
        return this.class.splitSentencesPromise(text).then((sentences) => classes_1.Collections.wrap(sentences).map((sentence) => ({
            text: sentence.text(),
            start: sentence.start(),
            end: sentence.end()
        })));
    }
    static splitSentencesSync(text) {
        return classes_1.Collections.wrap(this.class.splitSentences(text)).map((sentence) => ({
            text: sentence.text(),
            start: sentence.start(),
            end: sentence.end()
        }));
    }
    static extractPhrases(tokens, options) {
        options = Object.assign({ filterSpam: true, includeHashtag: false }, options);
        return this.class
            .extractPhrasesPromise(tokens.interface, options.filterSpam, options.includeHashtag)
            .then((phrasesSeq) => classes_1.Collections.wrap(phrasesSeq).map((phrase) => ({
            text: phrase.text(),
            pos: phrase.pos().toString(),
            offset: phrase.offset(),
            length: phrase.length()
        })));
    }
    static extractPhrasesSync(tokens, options) {
        options = Object.assign({ filterSpam: true, includeHashtag: false }, options);
        const phrasesSeq = classes_1.Collections.wrap(this.class.extractPhrases(tokens.interface, options.filterSpam, options.includeHashtag));
        return phrasesSeq.map((phrase) => ({
            text: phrase.text(),
            pos: phrase.pos().toString(),
            offset: phrase.offset(),
            length: phrase.length()
        }));
    }
    static detokenize() {
        let words;
        if (arguments[0] instanceof tokens_1.IntermediaryTokensObject) {
            words = arguments[0]
                .toJSON()
                .filter((token) => token.pos !== 'Space')
                .map((token) => token.text);
        }
        else if (Array.isArray(arguments[0])) {
            words = arguments[0];
        }
        else {
            words = Array.from(arguments);
        }
        const list = new classes_1.ArrayList(words);
        return this.class.detokenizePromise(list.interface).then((detokenized) => detokenized.toString());
    }
    static detokenizeSync() {
        let words;
        if (arguments[0] instanceof tokens_1.IntermediaryTokensObject) {
            words = arguments[0]
                .toJSON()
                .filter((token) => token.pos !== 'Space')
                .map((token) => token.text);
        }
        else if (Array.isArray(arguments[0])) {
            words = arguments[0];
        }
        else {
            words = Array.from(arguments);
        }
        const list = new classes_1.ArrayList(words);
        const detokenized = this.class.detokenize(list.interface);
        return detokenized.toString();
    }
}
OpenKoreanTextProcessor.className = 'org.openkoreantext.processor.OpenKoreanTextProcessorJava';
exports.OpenKoreanTextProcessor = OpenKoreanTextProcessor;
